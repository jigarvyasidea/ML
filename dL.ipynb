{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf88591-2894-48ff-95ca-c4471afa4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b825db2-12c6-4957-a1da-21be16001a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('abc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7537a1c-d7a4-4c0f-8b8a-e0da7563926f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text (Input)</th>\n",
       "      <th>Summary (Target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Aaj ka din kaafi thanda tha. Main apne dost ke...</td>\n",
       "      <td>Aaj ka din cricket khelne mein guzra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ghar ke kaam mein madad karne ke baad maine ap...</td>\n",
       "      <td>Ghar ke kaam ke baad book padha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Kal subah mujhe kaam par jaana tha, par meri c...</td>\n",
       "      <td>Car start nahi hui, taxi li.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Mujhe school jaana tha par baarish ho gayi. Ph...</td>\n",
       "      <td>Baarish ke wajah se school nahi jaa sakta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Main ne shopping mall jaana tha lekin wahan bo...</td>\n",
       "      <td>Mall mein bheed thi, ghar waapas gaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Main ne shopping mall jaana tha lekin wahan bo...</td>\n",
       "      <td>Mall mein bheed thi, ghar waapas gaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Mujhe ek dosti ki zarurat thi, toh main apni p...</td>\n",
       "      <td>Dosti karne gaya apni purani dost se.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>Aaj raat ko movie dekhna tha, par baarish ki w...</td>\n",
       "      <td>Baarish ki wajah se movie nahi dekh paaye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Aaj ka din kaafi thanda tha. Main apne dost ke...</td>\n",
       "      <td>Aaj ka din cricket khelne mein guzra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Main ne shopping mall jaana tha lekin wahan bo...</td>\n",
       "      <td>Mall mein bheed thi, ghar waapas gaya.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text (Input)  \\\n",
       "931  Aaj ka din kaafi thanda tha. Main apne dost ke...   \n",
       "29   Ghar ke kaam mein madad karne ke baad maine ap...   \n",
       "462  Kal subah mujhe kaam par jaana tha, par meri c...   \n",
       "200  Mujhe school jaana tha par baarish ho gayi. Ph...   \n",
       "273  Main ne shopping mall jaana tha lekin wahan bo...   \n",
       "893  Main ne shopping mall jaana tha lekin wahan bo...   \n",
       "744  Mujhe ek dosti ki zarurat thi, toh main apni p...   \n",
       "965  Aaj raat ko movie dekhna tha, par baarish ki w...   \n",
       "161  Aaj ka din kaafi thanda tha. Main apne dost ke...   \n",
       "623  Main ne shopping mall jaana tha lekin wahan bo...   \n",
       "\n",
       "                               Summary (Target)  \n",
       "931       Aaj ka din cricket khelne mein guzra.  \n",
       "29             Ghar ke kaam ke baad book padha.  \n",
       "462                Car start nahi hui, taxi li.  \n",
       "200  Baarish ke wajah se school nahi jaa sakta.  \n",
       "273      Mall mein bheed thi, ghar waapas gaya.  \n",
       "893      Mall mein bheed thi, ghar waapas gaya.  \n",
       "744       Dosti karne gaya apni purani dost se.  \n",
       "965  Baarish ki wajah se movie nahi dekh paaye.  \n",
       "161       Aaj ka din cricket khelne mein guzra.  \n",
       "623      Mall mein bheed thi, ghar waapas gaya.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e5dacd-8f67-4cfe-b661-37e1f7153201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Text (Input)      1000 non-null   object\n",
      " 1   Summary (Target)  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7ba56b-1832-45e7-a720-ac4f55c92a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text (Input)        0\n",
       "Summary (Target)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d24a03-3771-44df-a737-24bcf5edd43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22f7376-d975-479f-ba32-362b40adf346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 990 Duplicated rows hai \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5e173a4-2378-4f3d-a4d2-4a43499c163a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Volumes/Software/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Volumes/Software/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Volumes/Software/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Text'"
     ]
    }
   ],
   "source": [
    "df['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78eb1315-2699-4e57-806c-f75fe47f105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Text (Input)', 'Summary (Target)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a7ce25c-1a7e-43a0-b829-d59be2a2da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mujhe school jaana tha par baarish ho gayi. Phir, maine ghar se nikalne ka socha. Phir maine apni dost ko phone kiya...'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text (Input)'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14cf6c4b-a69f-4288-b90e-23dd10b5d5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baarish ke wajah se school nahi jaa sakta.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Summary (Target)'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c2300-1c7b-4a3e-b478-5e0fd11abd5d",
   "metadata": {},
   "source": [
    "# Data Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9746b84-fc16-4e72-a9e2-918a7108d780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text (Input)</th>\n",
       "      <th>Summary (Target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mujhe school jaana tha par baarish ho gayi. Ph...</td>\n",
       "      <td>Baarish ke wajah se school nahi jaa sakta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaj ka din kaafi thanda tha. Main apne dost ke...</td>\n",
       "      <td>Aaj ka din cricket khelne mein guzra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kal subah mujhe kaam par jaana tha, par meri c...</td>\n",
       "      <td>Car start nahi hui, taxi li.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Main ne shopping mall jaana tha lekin wahan bo...</td>\n",
       "      <td>Mall mein bheed thi, ghar waapas gaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mujhe ek dosti ki zarurat thi, toh main apni p...</td>\n",
       "      <td>Dosti karne gaya apni purani dost se.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Aaj raat ko movie dekhna tha, par baarish ki w...</td>\n",
       "      <td>Baarish ki wajah se movie nahi dekh paaye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Maine gym join kiya, aur roz morning walk ke l...</td>\n",
       "      <td>Roz gym aur morning walk karta hoon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Aaj kal kaafi kaam hai office mein, subah se s...</td>\n",
       "      <td>Office mein meetings chal rahi hain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Main apne cousins ke saath ghoomne gaya aur hu...</td>\n",
       "      <td>Cousins ke saath hill station ghooma.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Ghar ke kaam mein madad karne ke baad maine ap...</td>\n",
       "      <td>Ghar ke kaam ke baad book padha.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text (Input)  \\\n",
       "0    Mujhe school jaana tha par baarish ho gayi. Ph...   \n",
       "1    Aaj ka din kaafi thanda tha. Main apne dost ke...   \n",
       "2    Kal subah mujhe kaam par jaana tha, par meri c...   \n",
       "3    Main ne shopping mall jaana tha lekin wahan bo...   \n",
       "4    Mujhe ek dosti ki zarurat thi, toh main apni p...   \n",
       "..                                                 ...   \n",
       "995  Aaj raat ko movie dekhna tha, par baarish ki w...   \n",
       "996  Maine gym join kiya, aur roz morning walk ke l...   \n",
       "997  Aaj kal kaafi kaam hai office mein, subah se s...   \n",
       "998  Main apne cousins ke saath ghoomne gaya aur hu...   \n",
       "999  Ghar ke kaam mein madad karne ke baad maine ap...   \n",
       "\n",
       "                               Summary (Target)  \n",
       "0    Baarish ke wajah se school nahi jaa sakta.  \n",
       "1         Aaj ka din cricket khelne mein guzra.  \n",
       "2                  Car start nahi hui, taxi li.  \n",
       "3        Mall mein bheed thi, ghar waapas gaya.  \n",
       "4         Dosti karne gaya apni purani dost se.  \n",
       "..                                          ...  \n",
       "995  Baarish ki wajah se movie nahi dekh paaye.  \n",
       "996        Roz gym aur morning walk karta hoon.  \n",
       "997        Office mein meetings chal rahi hain.  \n",
       "998       Cousins ke saath hill station ghooma.  \n",
       "999            Ghar ke kaam ke baad book padha.  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "516d1e64-d2d3-44b6-93cd-88d8cddb706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preporcessing function \n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "\n",
    "df['Text (Input)'] = df['Text (Input)'].apply(preprocess)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05aee024-7244-43bf-b4f5-6f695d33621f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text (Input)</th>\n",
       "      <th>Summary (Target)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mujhe school jaana tha par baarish ho gayi phi...</td>\n",
       "      <td>Baarish ke wajah se school nahi jaa sakta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaj ka din kaafi thanda tha main apne dost ke ...</td>\n",
       "      <td>Aaj ka din cricket khelne mein guzra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kal subah mujhe kaam par jaana tha par meri ca...</td>\n",
       "      <td>Car start nahi hui, taxi li.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main ne shopping mall jaana tha lekin wahan bo...</td>\n",
       "      <td>Mall mein bheed thi, ghar waapas gaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mujhe ek dosti ki zarurat thi toh main apni pu...</td>\n",
       "      <td>Dosti karne gaya apni purani dost se.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>aaj raat ko movie dekhna tha par baarish ki wa...</td>\n",
       "      <td>Baarish ki wajah se movie nahi dekh paaye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>maine gym join kiya aur roz morning walk ke li...</td>\n",
       "      <td>Roz gym aur morning walk karta hoon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>aaj kal kaafi kaam hai office mein subah se sh...</td>\n",
       "      <td>Office mein meetings chal rahi hain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>main apne cousins ke saath ghoomne gaya aur hu...</td>\n",
       "      <td>Cousins ke saath hill station ghooma.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ghar ke kaam mein madad karne ke baad maine ap...</td>\n",
       "      <td>Ghar ke kaam ke baad book padha.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text (Input)  \\\n",
       "0    mujhe school jaana tha par baarish ho gayi phi...   \n",
       "1    aaj ka din kaafi thanda tha main apne dost ke ...   \n",
       "2    kal subah mujhe kaam par jaana tha par meri ca...   \n",
       "3    main ne shopping mall jaana tha lekin wahan bo...   \n",
       "4    mujhe ek dosti ki zarurat thi toh main apni pu...   \n",
       "..                                                 ...   \n",
       "995  aaj raat ko movie dekhna tha par baarish ki wa...   \n",
       "996  maine gym join kiya aur roz morning walk ke li...   \n",
       "997  aaj kal kaafi kaam hai office mein subah se sh...   \n",
       "998  main apne cousins ke saath ghoomne gaya aur hu...   \n",
       "999  ghar ke kaam mein madad karne ke baad maine ap...   \n",
       "\n",
       "                               Summary (Target)  \n",
       "0    Baarish ke wajah se school nahi jaa sakta.  \n",
       "1         Aaj ka din cricket khelne mein guzra.  \n",
       "2                  Car start nahi hui, taxi li.  \n",
       "3        Mall mein bheed thi, ghar waapas gaya.  \n",
       "4         Dosti karne gaya apni purani dost se.  \n",
       "..                                          ...  \n",
       "995  Baarish ki wajah se movie nahi dekh paaye.  \n",
       "996        Roz gym aur morning walk karta hoon.  \n",
       "997        Office mein meetings chal rahi hain.  \n",
       "998       Cousins ke saath hill station ghooma.  \n",
       "999            Ghar ke kaam ke baad book padha.  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a58f3153-f34f-47b2-ba86-2ec605409dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.17.2-cp312-cp312-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "Successfully installed torch-2.2.2 torchvision-0.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "029f11ee-0bce-4b8e-b9fe-dcb50f409135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ea31695-d2ae-448f-b5e7-6450449de86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1b562fc-e154-460f-bc7a-d50fbcde8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (24.3.1)\n",
      "Requirement already satisfied: sentencepiece in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip\n",
    "! pip install --upgrade sentencepiece transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4af32c5a-530e-4953-a5b8-7840ae63a6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (4.48.1)\n",
      "Requirement already satisfied: filelock in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (4.66.5)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from transformers[sentencepiece]) (4.25.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[sentencepiece]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[sentencepiece]) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/Software/opt/anaconda3/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "! pip install \"transformers[sentencepiece]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56094a27-487f-4b4d-9e13-c581e7a55934",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Model and tokenizer setup\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Using T5 architecture\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Set optimizer and loss function\u001b[39;00m\n\u001b[1;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "File \u001b[0;32m/Volumes/Software/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1690\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1690\u001b[0m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_backends)\n",
      "File \u001b[0;32m/Volumes/Software/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1678\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1676\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1678\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Model and tokenizer setup\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')  # Using T5 architecture\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Set optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop (simplified)\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for index, row in df.iterrows():\n",
    "        input_text = row['Text (Input)']\n",
    "        target_summary = row['Summary (Target)']\n",
    "        \n",
    "        # Tokenize inputs\n",
    "        input_ids = tokenizer(input_text, return_tensors='pt').input_ids\n",
    "        labels = tokenizer(target_summary, return_tensors='pt').input_ids\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {total_loss / len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef662bf1-7641-4da9-ad83-6cf7946d3df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
